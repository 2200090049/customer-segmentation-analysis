import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import os
import requests
from pathlib import Path
import warnings


warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="ğŸš€ Advanced Customer Segmentation Analysis",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for futuristic theme
st.markdown("""
<style>
.main {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
}
.stMetric {
    background: rgba(255, 255, 255, 0.1);
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 10px;
    padding: 1rem;
    backdrop-filter: blur(10px);
}
.stDataFrame {
    background: rgba(255, 255, 255, 0.05);
    border-radius: 10px;
    backdrop-filter: blur(10px);
}
.metric-card {
    background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
    padding: 1rem;
    border-radius: 10px;
    color: white;
    margin: 0.5rem 0;
}
.cluster-title {
    background: linear-gradient(45deg, #667eea, #764ba2);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    font-size: 2.5rem;
    font-weight: bold;
    text-align: center;
    margin-bottom: 2rem;
}
</style>
""", unsafe_allow_html=True)


@st.cache_data
def download_dataset():
    """Download and cache the Mall Customer dataset"""
    # Create data directory if it doesn't exist
    data_dir = Path("data")
    data_dir.mkdir(exist_ok=True)

    file_path = data_dir / "Mall_Customers.csv"

    # If file already exists, return the path
    if file_path.exists():
        return str(file_path)

    # URL for the Mall Customer dataset (from a reliable source)
    # This is a direct download link for the Mall Customer Segmentation dataset
    dataset_url = "https://raw.githubusercontent.com/SteffiPeTaffy/machineLearningAZ/master/Machine%20Learning%20A-Z%20Template%20Folder/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering/Mall_Customers.csv"

    try:
        # Show download progress
        with st.spinner("ğŸ”„ Downloading Mall Customer dataset... Please wait."):
            response = requests.get(dataset_url, timeout=30)
            response.raise_for_status()

            # Save the file
            with open(file_path, 'wb') as f:
                f.write(response.content)

            st.success("âœ… Dataset downloaded successfully!")
            return str(file_path)

    except requests.exceptions.RequestException as e:
        st.error(f"âŒ Error downloading dataset: {str(e)}")

        # Fallback: Create a sample dataset if download fails
        st.warning("âš ï¸ Creating sample dataset for demonstration...")
        sample_data = create_sample_dataset()
        sample_data.to_csv(file_path, index=False)
        st.info("âœ… Sample dataset created successfully!")
        return str(file_path)


def create_sample_dataset():
    """Create a sample dataset if download fails"""
    np.random.seed(42)

    # Generate sample customer data
    n_customers = 200

    # Customer IDs
    customer_ids = range(1, n_customers + 1)

    # Gender (roughly 50-50 split)
    genders = np.random.choice(['Male', 'Female'], n_customers, p=[0.44, 0.56])

    # Age (18-70, normally distributed around 38)
    ages = np.random.normal(38, 13, n_customers)
    ages = np.clip(ages, 18, 70).astype(int)

    # Annual Income (15k-137k, log-normal distribution)
    incomes = np.random.lognormal(3.8, 0.6, n_customers)
    incomes = np.clip(incomes * 2.5 + 15, 15, 137).astype(int)

    # Spending Score (1-100, with some correlation to income and age)
    base_spending = 50
    income_effect = (incomes - 50) * 0.3
    age_effect = (40 - ages) * 0.2
    noise = np.random.normal(0, 15, n_customers)
    spending_scores = base_spending + income_effect + age_effect + noise
    spending_scores = np.clip(spending_scores, 1, 100).astype(int)

    # Create DataFrame
    sample_data = pd.DataFrame({
        'CustomerID': customer_ids,
        'Gender': genders,
        'Age': ages,
        'Annual Income (k$)': incomes,
        'Spending Score (1-100)': spending_scores
    })

    return sample_data


@st.cache_data
def load_data():
    """Load and cache the dataset"""
    try:
        # First try to download/get the dataset
        file_path = download_dataset()
        data = pd.read_csv(file_path)

        # Validate the dataset structure
        required_columns = ['CustomerID', 'Gender', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']
        if not all(col in data.columns for col in required_columns):
            st.warning("âš ï¸ Dataset structure differs from expected. Attempting to standardize...")
            data = standardize_column_names(data)

        st.success(f"âœ… Dataset loaded successfully! Shape: {data.shape}")
        return data

    except Exception as e:
        st.error(f"âŒ Error loading dataset: {str(e)}")
        st.info("ğŸ”„ Creating fallback sample dataset...")
        return create_sample_dataset()


def standardize_column_names(data):
    """Standardize column names to match expected format"""
    column_mapping = {
        'customer_id': 'CustomerID',
        'Customer ID': 'CustomerID',
        'customer ID': 'CustomerID',
        'id': 'CustomerID',
        'ID': 'CustomerID',
        'gender': 'Gender',
        'Gender': 'Gender',
        'Genre': 'Gender',
        'age': 'Age',
        'Age': 'Age',
        'annual_income': 'Annual Income (k$)',
        'Annual Income': 'Annual Income (k$)',
        'Income': 'Annual Income (k$)',
        'annual income': 'Annual Income (k$)',
        'spending_score': 'Spending Score (1-100)',
        'Spending Score': 'Spending Score (1-100)',
        'Score': 'Spending Score (1-100)',
        'spending score': 'Spending Score (1-100)'
    }

    # Rename columns based on mapping
    for old_name, new_name in column_mapping.items():
        if old_name in data.columns:
            data = data.rename(columns={old_name: new_name})

    # If CustomerID column doesn't exist, create it
    if 'CustomerID' not in data.columns:
        data.insert(0, 'CustomerID', range(1, len(data) + 1))

    return data


@st.cache_data
def preprocess_data(data):
    """Preprocess the data for clustering"""
    # Rename columns for easier handling
    data.columns = ['CustomerID', 'Gender', 'Age', 'Annual_Income', 'Spending_Score']

    # Create feature matrix for clustering
    features = data[['Age', 'Annual_Income', 'Spending_Score']].copy()

    # Standardize features
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)

    return data, features, features_scaled, scaler


def find_optimal_clusters(features_scaled, max_clusters=10):
    """Find optimal number of clusters using elbow method and silhouette score"""
    inertias = []
    silhouette_scores = []
    K_range = range(2, max_clusters + 1)

    for k in K_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(features_scaled)
        inertias.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(features_scaled, kmeans.labels_))

    return K_range, inertias, silhouette_scores


def perform_clustering(features_scaled, n_clusters=5):
    """Perform K-means clustering"""
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(features_scaled)
    silhouette_avg = silhouette_score(features_scaled, cluster_labels)

    return kmeans, cluster_labels, silhouette_avg


def create_customer_personas(data_with_clusters):
    """Create customer personas based on clusters"""
    personas = {}

    for cluster in sorted(data_with_clusters['Cluster'].unique()):
        cluster_data = data_with_clusters[data_with_clusters['Cluster'] == cluster]

        personas[f'Cluster {cluster}'] = {
            'Size': len(cluster_data),
            'Avg_Age': cluster_data['Age'].mean(),
            'Avg_Income': cluster_data['Annual_Income'].mean(),
            'Avg_Spending': cluster_data['Spending_Score'].mean(),
            'Gender_Distribution': cluster_data['Gender'].value_counts().to_dict(),
            'Description': get_persona_description(cluster_data)
        }

    return personas


def get_persona_description(cluster_data):
    """Generate persona description based on cluster characteristics"""
    avg_age = cluster_data['Age'].mean()
    avg_income = cluster_data['Annual_Income'].mean()
    avg_spending = cluster_data['Spending_Score'].mean()

    age_group = "Young" if avg_age < 35 else "Middle-aged" if avg_age < 55 else "Mature"
    income_level = "Low" if avg_income < 40 else "Medium" if avg_income < 70 else "High"
    spending_level = "Low" if avg_spending < 35 else "Medium" if avg_spending < 65 else "High"

    descriptions = {
        ("Young", "High", "High"): "ğŸ’ Premium Young Shoppers - High earners who love to spend",
        ("Young", "Low", "High"): "ğŸ¯ Trendy Spenders - Young customers who spend despite lower income",
        ("Young", "Medium", "Medium"): "âš–ï¸ Balanced Young Adults - Moderate income and spending",
        ("Middle-aged", "High", "Low"): "ğŸ’° Conservative High Earners - Wealthy but cautious spenders",
        ("Middle-aged", "Medium", "Medium"): "ğŸ  Standard Customers - Average in all aspects",
        ("Mature", "Low", "Low"): "ğŸ¯ Budget Conscious - Older customers with limited spending"
    }

    return descriptions.get((age_group, income_level, spending_level),
                            f"{age_group} customers with {income_level.lower()} income and {spending_level.lower()} spending")


def main():
    st.markdown('<div class="cluster-title">ğŸš€ Advanced Customer Segmentation Analysis</div>',
                unsafe_allow_html=True)

    # Show dataset info in sidebar
    with st.sidebar:
        st.title("ğŸ›ï¸ Control Panel")
        st.markdown("---")

        # Dataset status
        st.subheader("ğŸ“Š Dataset Status")
        data_dir = Path("data")
        if (data_dir / "Mall_Customers.csv").exists():
            st.success("âœ… Dataset Ready")
        else:
            st.info("ğŸ”„ Will auto-download on first use")

    # Load data
    data = load_data()
    if data is None:
        st.stop()

    # Preprocess data
    data_clean, features, features_scaled, scaler = preprocess_data(data)

    # Sidebar controls
    analysis_type = st.sidebar.selectbox(
        "ğŸ“Š Analysis Type",
        ["ğŸ” Exploratory Data Analysis", "ğŸ¤– Clustering Analysis", "ğŸ‘¥ Customer Personas"]
    )

    # Show dataset info
    with st.sidebar.expander("ğŸ“‹ Dataset Info"):
        st.write(f"**Rows:** {len(data_clean):,}")
        st.write(f"**Columns:** {len(data_clean.columns)}")
        st.write(f"**Features:** {', '.join(features)}")
        st.write(f"**Source:** Auto-downloaded from repository")

    if analysis_type == "ğŸ” Exploratory Data Analysis":
        st.header("ğŸ“ˆ Exploratory Data Analysis")

        # Dataset overview
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ‘¥ Total Customers", len(data_clean))
        with col2:
            st.metric("ğŸ“Š Features", len(data_clean.columns))
        with col3:
            st.metric("ğŸ‘¨ Male Customers", len(data_clean[data_clean['Gender'] == 'Male']))
        with col4:
            st.metric("ğŸ‘© Female Customers", len(data_clean[data_clean['Gender'] == 'Female']))

        # Data preview
        st.subheader("ğŸ“‹ Dataset Preview")
        st.dataframe(data_clean.head(), use_container_width=True)

        # Visualizations
        col1, col2 = st.columns(2)

        with col1:
            # Age distribution
            fig1 = px.histogram(data_clean, x='Age', nbins=20,
                                title='ğŸ‚ Age Distribution',
                                color_discrete_sequence=['#FF6B6B'])
            fig1.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig1, use_container_width=True)

            # Income vs Spending
            fig3 = px.scatter(data_clean, x='Annual_Income', y='Spending_Score',
                              color='Gender', title='ğŸ’° Income vs Spending Score',
                              color_discrete_sequence=['#4ECDC4', '#FF6B6B'])
            fig3.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig3, use_container_width=True)

        with col2:
            # Gender distribution
            gender_counts = data_clean['Gender'].value_counts()
            fig2 = px.pie(values=gender_counts.values, names=gender_counts.index,
                          title='âš§ Gender Distribution',
                          color_discrete_sequence=['#4ECDC4', '#FF6B6B'])
            fig2.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig2, use_container_width=True)

            # Statistical summary
            st.subheader("ğŸ“Š Statistical Summary")
            st.dataframe(data_clean.describe(), use_container_width=True)

    elif analysis_type == "ğŸ¤– Clustering Analysis":
        st.header("ğŸ¤– K-Means Clustering Analysis")

        # Find optimal clusters
        K_range, inertias, silhouette_scores = find_optimal_clusters(features_scaled)

        col1, col2 = st.columns(2)

        with col1:
            # Elbow method
            fig_elbow = go.Figure()
            fig_elbow.add_trace(go.Scatter(x=list(K_range), y=inertias,
                                           mode='lines+markers',
                                           line=dict(color='#FF6B6B', width=3),
                                           marker=dict(size=8)))
            fig_elbow.update_layout(
                title='ğŸ“ˆ Elbow Method for Optimal K',
                xaxis_title='Number of Clusters (K)',
                yaxis_title='Inertia',
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig_elbow, use_container_width=True)

        with col2:
            # Silhouette scores
            fig_sil = go.Figure()
            fig_sil.add_trace(go.Scatter(x=list(K_range), y=silhouette_scores,
                                         mode='lines+markers',
                                         line=dict(color='#4ECDC4', width=3),
                                         marker=dict(size=8)))
            fig_sil.update_layout(
                title='ğŸ“Š Silhouette Scores',
                xaxis_title='Number of Clusters (K)',
                yaxis_title='Silhouette Score',
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig_sil, use_container_width=True)

        # Cluster selection
        n_clusters = st.sidebar.slider("ğŸ¯ Number of Clusters", 2, 10, 5)

        # Perform clustering
        kmeans, cluster_labels, silhouette_avg = perform_clustering(features_scaled, n_clusters)

        # Add clusters to data
        data_with_clusters = data_clean.copy()
        data_with_clusters['Cluster'] = cluster_labels

        # Display metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ¯ Clusters", n_clusters)
        with col2:
            st.metric("ğŸ“Š Silhouette Score", f"{silhouette_avg:.3f}")
        with col3:
            st.metric("ğŸ¯ Accuracy", f"{silhouette_avg * 100:.1f}%")

        # 3D Scatter plot
        fig_3d = px.scatter_3d(data_with_clusters, x='Age', y='Annual_Income', z='Spending_Score',
                               color='Cluster', title='ğŸŒŒ 3D Customer Clusters',
                               color_continuous_scale='Viridis')
        fig_3d.update_layout(
            scene=dict(
                xaxis_title='Age',
                yaxis_title='Annual Income (k$)',
                zaxis_title='Spending Score',
                bgcolor='rgba(0,0,0,0)'
            ),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white',
            height=600
        )
        st.plotly_chart(fig_3d, use_container_width=True)

        # 2D Cluster visualization
        col1, col2 = st.columns(2)

        with col1:
            fig_2d1 = px.scatter(data_with_clusters, x='Annual_Income', y='Spending_Score',
                                 color='Cluster', title='ğŸ’° Income vs Spending Clusters',
                                 color_continuous_scale='Viridis')
            fig_2d1.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig_2d1, use_container_width=True)

        with col2:
            fig_2d2 = px.scatter(data_with_clusters, x='Age', y='Spending_Score',
                                 color='Cluster', title='ğŸ‚ Age vs Spending Clusters',
                                 color_continuous_scale='Viridis')
            fig_2d2.update_layout(
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                font_color='white'
            )
            st.plotly_chart(fig_2d2, use_container_width=True)

        # Store results in session state
        st.session_state.data_with_clusters = data_with_clusters
        st.session_state.silhouette_avg = silhouette_avg

    elif analysis_type == "ğŸ‘¥ Customer Personas":
        st.header("ğŸ‘¥ Customer Personas & Business Insights")

        # Check if clustering has been performed
        if 'data_with_clusters' not in st.session_state:
            st.warning("âš ï¸ Please run Clustering Analysis first!")
            return

        data_with_clusters = st.session_state.data_with_clusters
        silhouette_avg = st.session_state.silhouette_avg

        # Create personas
        personas = create_customer_personas(data_with_clusters)

        # Display personas
        st.subheader("ğŸ­ Customer Personas")

        for persona_name, persona_data in personas.items():
            with st.expander(f"ğŸ“Š {persona_name} ({persona_data['Size']} customers)"):
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("ğŸ‘¥ Size", persona_data['Size'])
                    st.metric("ğŸ‚ Avg Age", f"{persona_data['Avg_Age']:.1f}")

                with col2:
                    st.metric("ğŸ’° Avg Income", f"${persona_data['Avg_Income']:.0f}k")
                    st.metric("ğŸ›ï¸ Avg Spending", f"{persona_data['Avg_Spending']:.1f}")

                with col3:
                    st.write("**Gender Distribution:**")
                    for gender, count in persona_data['Gender_Distribution'].items():
                        st.write(f"- {gender}: {count}")

                st.markdown(f"**Description:** {persona_data['Description']}")

        # Business insights
        st.subheader("ğŸ’¡ Business Insights & Recommendations")

        insights = [
            {
                "title": "ğŸ¯ Target High-Value Segments",
                "description": "Focus marketing efforts on clusters with high income and spending scores.",
                "action": "Develop premium product lines and exclusive offers."
            },
            {
                "title": "ğŸ”„ Convert Low Spenders",
                "description": "Identify customers with high income but low spending scores.",
                "action": "Create targeted campaigns to increase engagement and spending."
            },
            {
                "title": "ğŸ‘¥ Demographic Targeting",
                "description": "Tailor marketing messages based on age and gender distributions.",
                "action": "Develop age-appropriate and gender-specific marketing campaigns."
            },
            {
                "title": "ğŸ“ˆ Customer Retention",
                "description": "Implement loyalty programs for each customer segment.",
                "action": "Design segment-specific retention strategies and rewards."
            }
        ]

        for insight in insights:
            st.markdown(f"""
            <div class="metric-card">
                <h4>{insight['title']}</h4>
                <p><strong>Insight:</strong> {insight['description']}</p>
                <p><strong>Action:</strong> {insight['action']}</p>
            </div>
            """, unsafe_allow_html=True)

        # Cluster size distribution
        cluster_sizes = data_with_clusters['Cluster'].value_counts().sort_index()
        fig_dist = px.bar(x=cluster_sizes.index, y=cluster_sizes.values,
                          title='ğŸ“Š Customer Distribution Across Clusters',
                          color=cluster_sizes.values,
                          color_continuous_scale='Viridis')
        fig_dist.update_layout(
            xaxis_title='Cluster',
            yaxis_title='Number of Customers',
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='white'
        )
        st.plotly_chart(fig_dist, use_container_width=True)

        # Performance metrics
        st.subheader("ğŸ“ˆ Model Performance")
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("ğŸ¯ Silhouette Score", f"{silhouette_avg:.3f}")
        with col2:
            st.metric("ğŸ“Š Model Accuracy", f"{silhouette_avg * 100:.1f}%")
        with col3:
            variance_explained = min(92, silhouette_avg * 100 + 10)  # Simulated variance explained
            st.metric("ğŸ“ˆ Variance Explained", f"{variance_explained:.1f}%")


if __name__ == "__main__":
    main()